from Compiler import mpc_math

# Configuration
HORIZON = 5
N_ITERATIONS = 10
N_ROLLOUTS = 16
N_ELITES = 4
DT = sfix(1.0)
MAX_STEPS = 50

# Cost matrices
Q = sfix.Matrix(2, 2)
Q[0][0] = sfix(10.0)
Q[1][1] = sfix(10.0)
R = sfix.Matrix(2, 2)
R[0][0] = sfix(1.0)
R[1][1] = sfix(1.0)

CONTROL_MIN = sfix(-2.0)
CONTROL_MAX = sfix(2.0)

def dynamics(pos_x, pos_y, action_x, action_y):
    """Simple dynamics: position += action * dt"""
    new_x = pos_x + action_x * DT
    new_y = pos_y + action_y * DT
    return new_x, new_y

def cost_function(actions, pos_x, pos_y, goal_x, goal_y):
    """Compute trajectory cost over horizon"""
    total_cost = sfix(0)
    curr_x, curr_y = pos_x, pos_y
    
    @for_range(HORIZON)
    def _(t):
        action_x = actions[t * 2]
        action_y = actions[t * 2 + 1]
        
        next_x, next_y = dynamics(curr_x, curr_y, action_x, action_y)
        curr_x.update(next_x)
        curr_y.update(next_y)
        
        error_x = curr_x - goal_x
        error_y = curr_y - goal_y
        state_cost = Q[0][0] * error_x * error_x + Q[1][1] * error_y * error_y
        
        control_cost = R[0][0] * action_x * action_x + R[1][1] * action_y * action_y
        
        total_cost.update(total_cost + state_cost + control_cost)
    
    return total_cost

def sample_actions(mu, sigma):
    """Sample actions from normal distribution and clip to bounds"""
    actions = sfix.Array(HORIZON * 2)
    
    @for_range(HORIZON * 2)
    def _(i):
        sample = sfix.get_random(-1, 1) * sigma[i] + mu[i]
        clipped = sample.min(CONTROL_MAX).max(CONTROL_MIN)
        actions[i] = clipped
    
    return actions

def plan(pos_x, pos_y, goal_x, goal_y):
    """Cross-Entropy Method planning - returns full trajectory"""
    mu = sfix.Array(HORIZON * 2)
    sigma = sfix.Array(HORIZON * 2)
    
    @for_range(HORIZON * 2)
    def _(i):
        mu[i] = sfix(0)
        sigma[i] = sfix(1)
    
    @for_range(N_ITERATIONS)
    def _(iter_idx):
        trajectories = sfix.Matrix(N_ROLLOUTS, HORIZON * 2)
        costs = sfix.Array(N_ROLLOUTS)
        
        @for_range(N_ROLLOUTS)
        def _(rollout_idx):
            traj = sample_actions(mu, sigma)
            print_ln("Rollout %s/%s, trajectory: %s", rollout_idx, N_ROLLOUTS, traj.reveal())
            cost = cost_function(traj, pos_x, pos_y, goal_x, goal_y)
            costs[rollout_idx] = cost
            print_ln("Iteration %s/%s, rollout %s/%s, cost: %s", iter_idx, N_ITERATIONS, rollout_idx, N_ROLLOUTS, cost.reveal())
            
            @for_range(HORIZON * 2)
            def _(j):
                trajectories[rollout_idx][j] = traj[j]
        
        @for_range(HORIZON * 2)
        def _(i):
            sum_val = sfix(0)
            sum_sq = sfix(0)
            
            @for_range(N_ELITES)
            def _(elite_idx):
                val = trajectories[elite_idx][i]
                sum_val.update(sum_val + val)
                sum_sq.update(sum_sq + val * val)
            
            new_mu = sum_val / sfix(N_ELITES)
            variance = sum_sq / sfix(N_ELITES) - new_mu * new_mu
            new_sigma = mpc_math.sqrt(variance.max(sfix(0.01)))
            
            mu[i] = new_mu
            sigma[i] = new_sigma
    
    return sample_actions(mu, sigma)

# Main execution
print_ln("Starting MPC robot navigation")

# Party 0 (robot) provides goal and position via get_input_from(0)
# All parties call this - party 0 provides input, party 1 receives it
goal_x = sfix.get_input_from(0)
goal_y = sfix.get_input_from(0)
pos_x = sfix.get_input_from(0)
pos_y = sfix.get_input_from(0)
print_ln("Goal: (%s, %s)", goal_x.reveal(), goal_y.reveal())
print_ln("Initial position: (%s, %s)", pos_x.reveal(), pos_y.reveal())

print_ln("Starting MPC control loop")
# Main control loop
@for_range(MAX_STEPS)
def _(step):
    # Server (party 1) performs planning on secret data
    print_ln("Planning step %s", step)
    trajectory = plan(pos_x, pos_y, goal_x, goal_y)
    
    # Reveal full trajectory to party 0 (robot) only
    revealed_actions = sfix.Array(HORIZON * 2)
    @for_range(HORIZON * 2)
    def _(i):
        revealed_actions[i] = trajectory[i].reveal_to(0)
    
    # Party 0 executes first action locally (in cleartext)
    # We still update the shared position for next planning iteration
    action_x = trajectory[0]
    action_y = trajectory[1]
    
    new_x, new_y = dynamics(pos_x, pos_y, action_x, action_y)
    pos_x.update(new_x)
    pos_y.update(new_y)
    
    # Print progress (reveal to both parties)
    @if_((step % 5).reveal() == 0)
    def _():
        print_ln("Step %s: pos=(%s, %s)", 
                 step, pos_x.reveal(), pos_y.reveal())

# Final result
print_ln("Final position: (%s, %s)", pos_x.reveal(), pos_y.reveal())
final_dist_sq = (pos_x - goal_x) * (pos_x - goal_x) + (pos_y - goal_y) * (pos_y - goal_y)
final_dist = mpc_math.sqrt(final_dist_sq)
print_ln("Distance to goal: %s", final_dist.reveal())
